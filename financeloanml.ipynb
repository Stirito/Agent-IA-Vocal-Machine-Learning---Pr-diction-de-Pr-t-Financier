{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:11.013869Z",
     "iopub.status.busy": "2024-12-24T15:22:11.013427Z",
     "iopub.status.idle": "2024-12-24T15:22:12.348887Z",
     "shell.execute_reply": "2024-12-24T15:22:12.347703Z",
     "shell.execute_reply.started": "2024-12-24T15:22:11.013830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket_name = \"LE NOM DE TON BUCKET S3\"\n",
    "\n",
    "print(\"Utilisation de l'instance SageMaker dans la région {} et le bucket {}\".format(region, bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charger les données du DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset : https://www.kaggle.com/datasets/krishnaraj30/finance-loan-approval-prediction-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.351205Z",
     "iopub.status.busy": "2024-12-24T15:22:12.350690Z",
     "iopub.status.idle": "2024-12-24T15:22:12.381381Z",
     "shell.execute_reply": "2024-12-24T15:22:12.380158Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.351147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_file_path = './datasets/train.csv'\n",
    "test_file_path = './datasets/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse du Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.383260Z",
     "iopub.status.busy": "2024-12-24T15:22:12.382794Z",
     "iopub.status.idle": "2024-12-24T15:22:12.455480Z",
     "shell.execute_reply": "2024-12-24T15:22:12.454051Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.383211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "info = df_train.info() \n",
    "tete = df_train.head() \n",
    "data_shape = df_train.shape \n",
    "\n",
    "no_of_rows, no_of_columns = (data_shape) \n",
    "no_of_features = no_of_columns - 1\n",
    "tot_num_data = no_of_rows * no_of_columns\n",
    "\n",
    "\n",
    "print (f'Informations générales sur les données :\\n{info}')\n",
    "print ('-----------------------------------------------------------------------\\n')\n",
    "\n",
    "print (f'Dimensions des données :\\n{data_shape}\\n')\n",
    "\n",
    "print (f'Nombre de lignes : {no_of_rows}')\n",
    "print (f'Nombre de colonnes : {no_of_columns}')\n",
    "print (f'Nombre de features : {no_of_features}')\n",
    "print (f'Nombre total de données : {tot_num_data}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données sous forme de Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Données vue tableaux\")\n",
    "\n",
    "tete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion des valeurs nuls/Nan dans le Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.459089Z",
     "iopub.status.busy": "2024-12-24T15:22:12.458524Z",
     "iopub.status.idle": "2024-12-24T15:22:12.467347Z",
     "shell.execute_reply": "2024-12-24T15:22:12.466071Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.459001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "\n",
    "valeurs_null = df_train.isnull().sum()\n",
    "\n",
    "print ('Les données manquantes pour chaque colonne: \\n', valeurs_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completer les valeurs nulles dans le dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 types de données : \n",
    "\n",
    "- Catégorie (Gender, Married, Dependents, Self-employed, Credit history) -> Completer par le mode de la colonne\n",
    "\n",
    "- Numérique (Loan amount. Loan amount term) -> Completer par la moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pourquoi ? \n",
    "\n",
    "* Au lieu de supprimer et perdre beaucoup de données -> on complete par des valeurs non impactante\n",
    "\n",
    "* En régression logistique on ne peut avoir de valeur NaN\n",
    "\n",
    "Mode = valeur la plus fréquente\n",
    "\n",
    "on remplace par la valeur deja majoritaire ce qui n'influence pas le jeu de donnée\n",
    "\n",
    "Moyenne \n",
    "\n",
    "On complete par la moyenne ce qui influence que trés peu le jeu de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.496045Z",
     "iopub.status.busy": "2024-12-24T15:22:12.495667Z",
     "iopub.status.idle": "2024-12-24T15:22:12.517302Z",
     "shell.execute_reply": "2024-12-24T15:22:12.516028Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.496011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Compléter les valeurs manquantes pour les colonnes catégories\n",
    "\n",
    "df_train['Gender'] = df_train['Gender'].fillna(df_train['Gender'].mode()[0])\n",
    "df_train['Married'] = df_train['Married'].fillna(df_train['Married'].mode()[0])\n",
    "df_train['Dependents'] = df_train['Dependents'].fillna(df_train['Dependents'].mode()[0])\n",
    "df_train['Self_Employed'] = df_train['Self_Employed'].fillna(df_train['Self_Employed'].mode()[0])\n",
    "df_train['Credit_History'] = df_train['Credit_History'].fillna(df_train['Credit_History'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.519599Z",
     "iopub.status.busy": "2024-12-24T15:22:12.519139Z",
     "iopub.status.idle": "2024-12-24T15:22:12.534559Z",
     "shell.execute_reply": "2024-12-24T15:22:12.533305Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.519551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Compléter les valeurs manquantes pour les données numériques\n",
    "\n",
    "df_train['LoanAmount'] = df_train['LoanAmount'].fillna(df_train['LoanAmount'].mean())\n",
    "df_train['Loan_Amount_Term'] = df_train['Loan_Amount_Term'].fillna(df_train['Loan_Amount_Term'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.537298Z",
     "iopub.status.busy": "2024-12-24T15:22:12.536404Z",
     "iopub.status.idle": "2024-12-24T15:22:12.555111Z",
     "shell.execute_reply": "2024-12-24T15:22:12.553667Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.537236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Double check des valeurs nulles après le remplissage\n",
    "df_train.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:12.556777Z",
     "iopub.status.busy": "2024-12-24T15:22:12.556437Z",
     "iopub.status.idle": "2024-12-24T15:22:13.078423Z",
     "shell.execute_reply": "2024-12-24T15:22:13.077282Z",
     "shell.execute_reply.started": "2024-12-24T15:22:12.556744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Visualisation des données manquantes\n",
    "sns.heatmap(df_train.isnull(), cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:13.082934Z",
     "iopub.status.busy": "2024-12-24T15:22:13.082587Z",
     "iopub.status.idle": "2024-12-24T15:22:14.538742Z",
     "shell.execute_reply": "2024-12-24T15:22:14.537384Z",
     "shell.execute_reply.started": "2024-12-24T15:22:13.082899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Using scatterplot to check for outliers\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "num_columns = ['LoanAmount', 'Loan_Amount_Term', 'ApplicantIncome', 'CoapplicantIncome']\n",
    "scatter_matrix(df_train[num_columns], figsize = (12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:14.541188Z",
     "iopub.status.busy": "2024-12-24T15:22:14.540669Z",
     "iopub.status.idle": "2024-12-24T15:22:22.450394Z",
     "shell.execute_reply": "2024-12-24T15:22:22.449178Z",
     "shell.execute_reply.started": "2024-12-24T15:22:14.541134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:22.452476Z",
     "iopub.status.busy": "2024-12-24T15:22:22.452112Z",
     "iopub.status.idle": "2024-12-24T15:22:22.829515Z",
     "shell.execute_reply": "2024-12-24T15:22:22.828352Z",
     "shell.execute_reply.started": "2024-12-24T15:22:22.452443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Further examination of numerical outliers\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.boxplot(data=df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:22.831546Z",
     "iopub.status.busy": "2024-12-24T15:22:22.831095Z",
     "iopub.status.idle": "2024-12-24T15:22:23.221542Z",
     "shell.execute_reply": "2024-12-24T15:22:23.220290Z",
     "shell.execute_reply.started": "2024-12-24T15:22:22.831497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "Outlier_check = df_train[num_columns]\n",
    "sns.stripplot(data = Outlier_check, palette='dark:red', jitter = 0.3, size = 5)\n",
    "\n",
    "plt.title('Outlier Check')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T07:12:29.133615Z",
     "iopub.status.busy": "2024-10-14T07:12:29.133254Z",
     "iopub.status.idle": "2024-10-14T07:12:29.138076Z",
     "shell.execute_reply": "2024-10-14T07:12:29.136832Z",
     "shell.execute_reply.started": "2024-10-14T07:12:29.133576Z"
    }
   },
   "source": [
    "### Données catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:23.223586Z",
     "iopub.status.busy": "2024-12-24T15:22:23.223131Z",
     "iopub.status.idle": "2024-12-24T15:22:25.207936Z",
     "shell.execute_reply": "2024-12-24T15:22:25.206714Z",
     "shell.execute_reply.started": "2024-12-24T15:22:23.223516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualisng all categorical columns at once\n",
    "cat_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
    "\n",
    "\n",
    "#setting up plotting environment\n",
    "num_cat = len(cat_columns)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_cat, ncols=1, figsize = (10, 5*num_cat))\n",
    "\n",
    "#Plotting barchat of each categorical columns\n",
    "for i, col in enumerate(cat_columns):\n",
    "    sns.countplot(data=df_train, x=col, ax=axes[i], hue='Loan_Status', palette='Set2')\n",
    "    axes[i].set_title(f'plot of {col}')\n",
    "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation = 45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:25.209923Z",
     "iopub.status.busy": "2024-12-24T15:22:25.209516Z",
     "iopub.status.idle": "2024-12-24T15:22:25.224462Z",
     "shell.execute_reply": "2024-12-24T15:22:25.222406Z",
     "shell.execute_reply.started": "2024-12-24T15:22:25.209877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dependents_0 = df_train[df_train['Dependents'] == '0']\n",
    "total_dependents_0 = len(dependents_0)\n",
    "loan_status_no = dependents_0[dependents_0['Loan_Status'] == 'No']\n",
    "percent_loan_status_no = (len(loan_status_no)/total_dependents_0)*100\n",
    "\n",
    "percent_loan_status_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:25.226126Z",
     "iopub.status.busy": "2024-12-24T15:22:25.225759Z",
     "iopub.status.idle": "2024-12-24T15:22:25.273169Z",
     "shell.execute_reply": "2024-12-24T15:22:25.271764Z",
     "shell.execute_reply.started": "2024-12-24T15:22:25.226091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Filter rows where Dependents is '0'\n",
    "dependents_zero = df_train[df_train['Dependents'] == '0']\n",
    "\n",
    "# Step 2: Calculate the total number of Dependents '0'\n",
    "total_dependents_zero = len(dependents_zero)\n",
    "total_dependents_notzero = len(df_train[df_train['Dependents'] != '0'])\n",
    "\n",
    "# Step 3: Filter rows where Loan_Status is 'No' from the dependents_zero subset\n",
    "loan_status_no = dependents_zero[dependents_zero['Loan_Status'] == 'N']\n",
    "\n",
    "# Step 4: Calculate the percentage of Loan_Status 'No' in Dependents '0'\n",
    "percentage_no_loan = (len(loan_status_no) / total_dependents_zero) * 100\n",
    "\n",
    "print(f\"Total number of Dependents '0': {total_dependents_zero}\")\n",
    "print(f\"Total number of Dependents not '0': {total_dependents_notzero}\")\n",
    "print(f\"Percentage of Dependents '0' with Loan_Status 'No': {percentage_no_loan:.2f}%\")\n",
    "print (len(df_train['Dependents']))\n",
    "print (len(loan_status_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestions des données improbables/aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T09:00:42.700613Z",
     "iopub.status.busy": "2024-10-14T09:00:42.699587Z",
     "iopub.status.idle": "2024-10-14T09:00:42.707674Z",
     "shell.execute_reply": "2024-10-14T09:00:42.706012Z",
     "shell.execute_reply.started": "2024-10-14T09:00:42.700562Z"
    }
   },
   "source": [
    "Nous utilisons l'amplitude interquartile (IQR) pour identifier les valeurs aberrantes.\n",
    "\n",
    "Conventionnellement, les valeurs situées en dehors de 1,5 × IQR sont généralement considérées comme des valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:25.275275Z",
     "iopub.status.busy": "2024-12-24T15:22:25.274713Z",
     "iopub.status.idle": "2024-12-24T15:22:25.293787Z",
     "shell.execute_reply": "2024-12-24T15:22:25.292719Z",
     "shell.execute_reply.started": "2024-12-24T15:22:25.275219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Calcul IQR pour Applicantincome\n",
    "\n",
    "Q1_app = df_train['ApplicantIncome'].quantile(0.25)\n",
    "Q3_app = df_train['ApplicantIncome'].quantile(0.75)\n",
    "IQR = Q3_app - Q1_app\n",
    "\n",
    "lowerbound_app = Q1_app - 1.5*IQR\n",
    "upperbound_app = Q3_app + 1.5*IQR\n",
    "\n",
    "outliers_app = df_train[(df_train['ApplicantIncome'] < lowerbound_app) | (df_train['ApplicantIncome'] > upperbound_app)]\n",
    "\n",
    "#Calcul IQR pour CoapplicantIncome\n",
    "\n",
    "Q1_co = df_train['CoapplicantIncome'].quantile(0.25)\n",
    "Q3_co = df_train['CoapplicantIncome'].quantile(0.75)\n",
    "IQR_co = Q3_co - Q1_co\n",
    "\n",
    "lowerbound_co = Q1_co - 1.5*IQR_co\n",
    "upperbound_co = Q3_co + 1.5*IQR_co\n",
    "\n",
    "outliers_co = df_train[(df_train['CoapplicantIncome'] < lowerbound_co) | (df_train['CoapplicantIncome'] > upperbound_co)]\n",
    "\n",
    "#Suppression des données improbables\n",
    "df_train = df_train[~((df_train['ApplicantIncome'] < lowerbound_app) | (df_train['ApplicantIncome'] > upperbound_app))]\n",
    "df_train = df_train[~((df_train['CoapplicantIncome'] < lowerbound_co) | (df_train['CoapplicantIncome'] > upperbound_co))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:25.295872Z",
     "iopub.status.busy": "2024-12-24T15:22:25.295397Z",
     "iopub.status.idle": "2024-12-24T15:22:25.637102Z",
     "shell.execute_reply": "2024-12-24T15:22:25.636030Z",
     "shell.execute_reply.started": "2024-12-24T15:22:25.295816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 9))\n",
    "\n",
    "outlier_check2 = df_train[num_columns]\n",
    "sns.stripplot(data=outlier_check2, palette='dark:red', jitter = 0.3, size = 5)\n",
    "plt.show()\n",
    "\n",
    "print ('Dimension du dataset après avoir traité les données improbables : ', df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obervations de corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:25.639001Z",
     "iopub.status.busy": "2024-12-24T15:22:25.638585Z",
     "iopub.status.idle": "2024-12-24T15:22:26.191115Z",
     "shell.execute_reply": "2024-12-24T15:22:26.189827Z",
     "shell.execute_reply.started": "2024-12-24T15:22:25.638936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Selection des colonnes numériques uniquement\n",
    "numeric_df = df_train.select_dtypes(include=[np.number]) \n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On peut observer que Applicant Income est corréléer à Loan_Status\n",
    "* CoApplicant aussi mais légérement moins corréler\n",
    "\n",
    "#### Rappel \n",
    "\n",
    "Plus la valeur est proche de 1 plus la variable est corrélée et inversement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering (ou l'art de combiner des variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoding des valeurs de Catégories\n",
    "\n",
    "Les valeurs de catégories vont être convertis en valeurs numériques faciliter le modèle (et faire la Régression Logistique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.193145Z",
     "iopub.status.busy": "2024-12-24T15:22:26.192731Z",
     "iopub.status.idle": "2024-12-24T15:22:26.210475Z",
     "shell.execute_reply": "2024-12-24T15:22:26.209061Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.193110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns = cat_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation des features (valeurs X)\n",
    "\n",
    "- Simplifie les calculs (+ rapide)\n",
    "\n",
    "\n",
    "### !!! Veiller à \"dé-normaliser\" aussi les valeurs tests pour obtenir les bonnes valeurs !!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()[[\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_income = df_train['ApplicantIncome'].max()\n",
    "max_co_income = df_train['CoapplicantIncome'].max()\n",
    "max_loan_amount = df_train['LoanAmount'].max()\n",
    "\n",
    "min_income = df_train['ApplicantIncome'].min()\n",
    "min_co_income = df_train['CoapplicantIncome'].min()\n",
    "min_loan_amount = df_train['LoanAmount'].min()\n",
    "\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Maximum ApplicantIncome: {max_income}\")\n",
    "print(f\"Minimum ApplicantIncome: {min_income}\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Maximum CoapplicantIncome: {max_co_income}\")\n",
    "print(f\"Minimum CoapplicantIncome: {min_co_income}\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Maximum LoanAmount: {max_loan_amount}\")\n",
    "print(f\"Minimum LoanAmount: {min_loan_amount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.212892Z",
     "iopub.status.busy": "2024-12-24T15:22:26.212500Z",
     "iopub.status.idle": "2024-12-24T15:22:26.309730Z",
     "shell.execute_reply": "2024-12-24T15:22:26.308679Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.212855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler= StandardScaler()\n",
    "\n",
    "df_train[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']] = standard_scaler.fit_transform(df_train[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "scaler_params = {\n",
    "    'mean': standard_scaler.mean_.tolist(),\n",
    "    'scale': standard_scaler.scale_.tolist()\n",
    "}\n",
    "\n",
    "scaler_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler_params.json', 'w') as f:\n",
    "    json.dump(scaler_params, f)\n",
    "    \n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file('scaler_params.json', bucket_name, 'scalers/scaler_params.json')\n",
    "s3_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:12:57.767022Z",
     "iopub.status.busy": "2024-10-14T15:12:57.766016Z",
     "iopub.status.idle": "2024-10-14T15:12:57.778106Z",
     "shell.execute_reply": "2024-10-14T15:12:57.7768Z",
     "shell.execute_reply.started": "2024-10-14T15:12:57.766951Z"
    }
   },
   "source": [
    "## Création de nouvelles features\n",
    "\n",
    "Combiner des valeurs pour créer de nouvelles variables\n",
    "\n",
    "Nouvelles relations :\n",
    "\n",
    "* Total Income = Applicant Income + Co-applicant income\n",
    "* Loan-to-income ratio = Loan amount / Total income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourquoi ?\n",
    "\n",
    "- Permet de réduire le nombre de données \n",
    "- éviter le over-fitting\n",
    "\n",
    "over-fitting : quand le modèle apprend trop précisement les données et donc évite la généralisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.311834Z",
     "iopub.status.busy": "2024-12-24T15:22:26.311303Z",
     "iopub.status.idle": "2024-12-24T15:22:26.339137Z",
     "shell.execute_reply": "2024-12-24T15:22:26.338025Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.311788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Total Income\n",
    "\n",
    "df_train['Total_Income'] = df_train['ApplicantIncome'] + df_train['CoapplicantIncome']\n",
    "\n",
    "#Loan-to-income Ratio\n",
    "\n",
    "df_train['Loan_to_Income'] = df_train['LoanAmount']/df_train['Total_Income'] \n",
    "\n",
    "# Viewing the updated features\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pourcentage de répartition des classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.340699Z",
     "iopub.status.busy": "2024-12-24T15:22:26.340372Z",
     "iopub.status.idle": "2024-12-24T15:22:26.351163Z",
     "shell.execute_reply": "2024-12-24T15:22:26.350003Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.340668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['Loan_Status_Y'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourquoi ? \n",
    "\n",
    "Les données de la vie réelle sont un gros bordel. \n",
    "\n",
    "Donc ca nous permet d'identifier : \n",
    "\n",
    "- Un déséquilibre des classes\n",
    "- ajuster les techniques de modélisations\n",
    "- savoir quel métriques(valeurs) d'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas présent la répartition est bonne.\n",
    "\n",
    "Pas besoin donc de rajouter des valeurs ou de les corriger pour l'overfitting ou underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.352793Z",
     "iopub.status.busy": "2024-12-24T15:22:26.352476Z",
     "iopub.status.idle": "2024-12-24T15:22:26.382058Z",
     "shell.execute_reply": "2024-12-24T15:22:26.380752Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.352762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# On va supprimer les colonnes Loan_ID et Loan_Amount_Term\n",
    "\n",
    "df_train = df_train.drop(['Loan_ID', 'Loan_Amount_Term'], axis=1)\n",
    "\n",
    "column_update = {'Gender_Male': 'Gender', 'Married_Yes': 'Married',\n",
    "                'Self_Employed_Yes': 'Self_Employed', 'Loan_Status_Y': 'Loan_Status' }\n",
    "\n",
    "df_train.rename(columns=column_update, inplace=True)\n",
    "\n",
    "#Display updated dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:45:07.404046Z",
     "iopub.status.busy": "2024-10-14T15:45:07.403388Z",
     "iopub.status.idle": "2024-10-14T15:45:07.426254Z",
     "shell.execute_reply": "2024-10-14T15:45:07.42481Z",
     "shell.execute_reply.started": "2024-10-14T15:45:07.403986Z"
    }
   },
   "source": [
    "# Construction du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "\n",
    "1. Séparer le Dataset en Features (X) and Targets (Y)\n",
    "\n",
    "2. Train-Test Split: Split data into training and test sets (80% train, 20% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.383986Z",
     "iopub.status.busy": "2024-12-24T15:22:26.383602Z",
     "iopub.status.idle": "2024-12-24T15:22:26.398459Z",
     "shell.execute_reply": "2024-12-24T15:22:26.397041Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.383924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = list(df_train.columns)\n",
    "print(features)\n",
    "label = features.pop(-1)\n",
    "\n",
    "X = df_train[features] #Features\n",
    "\n",
    "Y = df_train[\"Loan_Status\"] #Target\n",
    "\n",
    "print ('Shape of X: ', X.shape)\n",
    "print ('Shape of Y: ', Y.shape)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation de Scikit-Learn\n",
    "\n",
    "Documentation : https://scikit-learn.org/0.21/tutorial/basic/tutorial.html\n",
    "\n",
    "Vidéo sur le sujet : https://www.youtube.com/watch?v=0B5eIE_1vpU&pp=ygUSc2Npa2l0IGxlYXJuIGJhc2lj\n",
    "\n",
    "Livre Hands on Machine Learning: https://www.amazon.fr/Hands-Machine-Learning-Scikit-learn-Tensorflow/dp/1098125975/ref=asc_df_1098125975?mcid=c65f200626d13a1ab3d5944cd898aebd&tag=googshopfr-21&linkCode=df0&hvadid=701510839370&hvpos=&hvnetw=g&hvrand=15667932878931070552&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9109552&hvtargid=pla-1651497364252&psc=1&gad_source=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T15:22:26.400231Z",
     "iopub.status.busy": "2024-12-24T15:22:26.399818Z",
     "iopub.status.idle": "2024-12-24T15:22:26.535190Z",
     "shell.execute_reply": "2024-12-24T15:22:26.534045Z",
     "shell.execute_reply.started": "2024-12-24T15:22:26.400180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données sur S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('train-V-1.csv', index=False)\n",
    "X_test.to_csv('test-V-1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prefix = \"sagemaker/finance-loan-prediction/sklearncontainer\"\n",
    "\n",
    "train_path_s3 = sess.upload_data(path=\"train-V-1.csv\", bucket=bucket_name, key_prefix=sk_prefix)\n",
    "\n",
    "test_path_s3 = sess.upload_data(path=\"test-V-1.csv\", bucket=bucket_name, key_prefix=sk_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training data uploaded to: {train_path_s3}\")\n",
    "print(f\"Test data uploaded to: {test_path_s3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import sklearn\n",
    "import joblib\n",
    "import boto3\n",
    "import pathlib\n",
    "from io import StringIO \n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# inference functions ---------------\n",
    "\n",
    "# def input_fn(request_body, request_content_type):\n",
    "#     print(request_body)\n",
    "#     print(request_content_type)\n",
    "#     if request_content_type == \"text/csv\":\n",
    "#         request_body = request_body.strip()\n",
    "#         try:\n",
    "#             df = pd.read_csv(StringIO(request_body), header=None)\n",
    "#             return df\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#     else:\n",
    "#         return \"\"\"Please use Content-Type = 'text/csv' and, send the request!!\"\"\" \n",
    " \n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "# def predict_fn(input_data, model):\n",
    "#     if type(input_data) != str:\n",
    "#         prediction = model.predict(input_data)\n",
    "#         print(prediction)\n",
    "#         return prediction\n",
    "#     else:\n",
    "#         return input_data\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"[INFO] Extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    parser.add_argument(\"--random_state\", type=int, default=0)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train-V-1.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test-V-1.csv\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"SKLearn Version: \", sklearn.__version__)\n",
    "    print(\"Joblib Version: \", joblib.__version__)\n",
    "\n",
    "    print(\"[INFO] Reading data\")\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    features = [col for col in train_df.columns if col != 'Loan_Status']\n",
    "    label = \"Loan_Status\"\n",
    "    \n",
    "    print(\"Building training and testing datasets\")\n",
    "    print()\n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    y_train = train_df[label]\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print('Column order: ')\n",
    "    print(features)\n",
    "    print()\n",
    "    \n",
    "    print(\"Label column is: \",label)\n",
    "    print()\n",
    "    \n",
    "    print(\"Data Shape: \")\n",
    "    print()\n",
    "    print(\"---- SHAPE OF TRAINING DATA (80%) ----\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print()\n",
    "    print(\"---- SHAPE OF TESTING DATA (20%) ----\")\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print()\n",
    "    \n",
    "  \n",
    "    print(\"Training RandomForest Model.....\")\n",
    "    print()\n",
    "    model =  RandomForestClassifier(n_estimators=args.n_estimators, random_state=args.random_state, verbose = 3,n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model,model_path)\n",
    "    print(\"Model persisted at \" + model_path)\n",
    "    print()\n",
    "\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test,y_pred_test)\n",
    "    test_rep = classification_report(y_test,y_pred_test)\n",
    "\n",
    "    print()\n",
    "    print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n",
    "    print()\n",
    "    print(\"Total Rows are: \", X_test.shape[0])\n",
    "    print('[TESTING] Model Accuracy is: ', test_acc)\n",
    "    print('[TESTING] Testing Report: ')\n",
    "    print(test_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python script.py --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=\"TON EXECUTION ROLE ARN\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"RF-custom-sklearn\",\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 100,\n",
    "        \"random_state\": 0,\n",
    "    },\n",
    "    use_spot_instances = True,\n",
    "    max_wait = 7200,\n",
    "    max_run = 3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": train_path_s3, \"test\": test_path_s3}, wait=True)\n",
    "# sklearn_estimator.fit({\"train\": datapath}, wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact persisted at \" + artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model = SKLearnModel(\n",
    "    name=model_name,\n",
    "    model_data=artifact,\n",
    "    role=\"TON EXECUTION ROLE ARN\",\n",
    "    entry_point=\"script.py\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_file_path)\n",
    "\n",
    "cat_columns_test = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area']\n",
    "\n",
    "\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns = cat_columns_test, drop_first=True)\n",
    "\n",
    "column_update = {'Gender_Male': 'Gender', 'Married_Yes': 'Married',\n",
    "                'Self_Employed_Yes': 'Self_Employed', 'Loan_Status_Y': 'Loan_Status' }\n",
    "\n",
    "df_test.rename(columns=column_update, inplace=True)\n",
    "\n",
    "df_test = df_test.drop(['Loan_ID', 'Loan_Amount_Term'], axis=1)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']] = standard_scaler.transform(df_test[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']])\n",
    "\n",
    "df_test['Total_Income'] = df_test['ApplicantIncome'] + df_test['CoapplicantIncome']\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valeur_test = df_test[[col for col in df_test.columns if col != 'Loan_Status']][0:5]\n",
    "\n",
    "valeur_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.predict(valeur_test))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3378270,
     "sourceId": 5877232,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
